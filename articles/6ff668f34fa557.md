---
title: "レコメンド系kaggleコンペまとめ"
emoji: "👋"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["kaggle","レコメンド"]
published: false
---

# はじめに

この記事は[BrainPad Advent Calendar 2022](https://qiita.com/advent-calendar/2022/brainpad)の8日目の記事です。過去にあったいくつかのレコメンド系コンペの概要と上位解法のまとめです。解説ではなく今後調査するための備忘録の位置付けです。

# H&M Personalized Fashion Recommendations

## 概要

- H&Mのオンライン・オフラインの行動履歴をもとに、次にユーザーが購買する商品を予測するコンペ。
- 提供されたデータは約二年間のユーザーの行動データ。大別して下記の三種類に分けられる。
  - ユーザーデータ: 年齢、ハッシュ化された住所、会員登録の状況などデータ数は137万件程度。
  - アイテムデータ: 商品のカテゴリ、色・模様、商品の説明文(英語)、商品画像などで10万件程度。
  - トランザクションデータ: 日付、オンラインかオフラインかなど、データ数は3000万件程度。
- 評価指標はユーザーごとに予測対象の商品の中から12個予測した時のMAP@k。
  - レコメンデーションで一般的な評価指標。
  - 予測したものの中にユーザが実際に購入した商品があればスコアがつく。
  - 予測対象には順序があり購入した商品が上位にあるほどスコアが上がる。

## 上位解法の特徴抜粋

- 基本方針としては購入される商品の候補生成からのランク付けという流れ。候補生成はルールベースも用いられていた。
- 二値分類を使ったランク付け。
- graph embedding(ProNE)によるユーザとアイテムの類似度を用いた候補生成。また、類似度を特徴量に利用。
- Bayesian Personalized Ranking(BPR)を使用した特徴量生成。ユーザの購入アイテムとサンプリングした未観測アイテムを用いて、購入アイテムとユーザのベクトルが近づくように学習。類似度を特徴量に利用。
- word2vecによるアイテム間の類似度。
- 各候補生成時の候補内での商品数を特徴量にする(例：先週の人気アイテムtop nを候補に追加するならそのnを特徴として入れる)。
- 商品、ユーザの連続購買回数。
- 協調フィルタリング系。
- ユーザが過去に購入した商品をconcatして文章と見なして、特徴量生成。

## その他Tips

- ユーザー、アイテムのIDやカテゴリなどの文字列を最初から連番の整数に変換しておくことで、省メモリになるうえ、コードが簡潔になる。
- 毎回全てのデータで計算すると時間がかかりすぎて実験サイクルが遅いので、ユーザーを1%, 10%サンプリングしたデータセットで実験する。
- catboost-gpuでlgbの30倍高速化。
- feature storeで特徴生成を短縮。

## 参考

- [H&M Personalized Fashion Recommendations | Kaggle](<https://www.kaggle.com/c/h-and-m-personalized-fashion-recommendations>)
- [実務でレコメンドをやっているのでKaggle H&Mコンペに参加しました](<https://yng87.page/blog/2022/05/kaggle_hm/>)
- [DeNA・MoT AI技術共有会発表資料 H&Mコンペの振り返り - Speaker Deck](<https://speakerdeck.com/kuto5046/denamot-aiji-shu-gong-you-hui-fa-biao-zi-liao-h-and-mkonpefalsezhen-rifan-ri?slide=6>)
- [H&M Personalized Fashion Recommendations 参加記 (46th/2952) | フューチャー技術ブログ](<https://future-architect.github.io/articles/20220602b/>)
- [Recruit Data Blog | KaggleのH&M Personalized Fashion Recommendationsで11位金メダルを獲得しました](<https://blog.recruit.co.jp/data/articles/kaggle-h-and-m/#%E4%BB%96%E3%81%AE%E4%B8%8A%E4%BD%8D%E8%A7%A3%E6%B3%95%E3%81%A8%E3%81%AE%E6%AF%94%E8%BC%83>)

# Elo Merchant Category Recommendation

## 概要

- クレジットカードの購買データをもとに、顧客ロイヤリティスコア(データの提供元の決済サービス企業Eloが定義したスコア)を予測するコンペ。
- 提供されたデータは約20万件のカードの購買データ、予測対象のカードは12万件程度。下記の三種類。
  - 各カードを一意に識別できるIDとロイヤリティスコアを持つカードマスタ。ロイヤリティスコアはおおよそ0を中心とした-10から10程度の正規分布だが、-33付近に外れ値が存在。
  - カードごとの取引履歴データ。
  - カードが使われた店舗の購買データ。
- 評価指標はRMSE。

## 上位解法の特徴抜粋

- 外れ値を予測する2値分類モデルを使って、外れ値と外れ値抜きで学習した予測値を加重平均する。外れ値の確率が低いものについては、外れ値抜きで学習させたモデルでの予測値と差し替える方法は公開コードにもあった。
- 取引履歴データにロイヤリティスコアをマージして集約統計量を作成。
- ロイヤリティスコアを[0, 1]の範囲に正規化し、xentropy lossを最小化。
- target encoding
  - targetの値そのものを使ったり、外れ値かどうかのバイナリを利用など。
  - また、特徴量の組み合わせに対してtarget encodingを行った後、最近のものほど重要視されるように重みをつけて集約。
- 利用した店のidや購買量を文字列で並べてベクトル化。
- コルモゴロフ-スミルノフ検定を利用し、trainとtestで分布の違う特徴量を削除
  - 2つの母集団の確率分布が異なるかどうかを調べる検定
  - [Reducing the gap between CV and LB](<https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/77537>)
- magic featureを予測し、本来の値との誤差を特徴量にする

## 参考

- [Elo Merchant Category Recommendation | Kaggle](<https://www.kaggle.com/c/elo-merchant-category-recommendation>)
- [kaggle:Elo Merchant Category Recommendationコンペのまとめ - Qiita](<https://qiita.com/makotu1208/items/f10855aec2e67b4a44d1>)
- [Kaggle Eloコンペの振り返り・上位解法まとめ - 天色グラフィティ](<https://amalog.hateblo.jp/entry/elo-merchant-category-recommendation>)
- [Kaggleコンペティション体験記：ELO MERCHANT CATEGORY RECOMMENDATION - GMOインターネットグループ グループ研究開発本部（次世代システム研究室）](<https://recruit.gmo.jp/engineer/jisedai/blog/kaggle_elo_merchant_yt/>)

# Instacart Market Basket Analysis

## 概要

- オンライン食料品配達サービスで既存のユーザーが次回のページ訪問で再購入する商品を予測するコンペ。
- 提供されたデータはユーザが過去に購入したログデータ。ユーザー数は約20万、商品数は約5万、合計の注文回数は約340万。
- 注文IDごとに任意の数の商品を予測し、F1-scoreで評価。

## 上位解法の特徴抜粋

- F1 maximization：[Get Expected F1-Score in O(n²)](<https://www.kaggle.com/competitions/instacart-market-basket-analysis/discussion/37221>)
- NNによる特徴抽出（例：ユーザが時間帯ごとに商品を予測する確率を予測など）を行い特徴量に利用。
- 注文しない場合を予測：[Predicting "None"](<https://www.kaggle.com/c/instacart-market-basket-analysis/discussion/35716>)
- 特徴量([2位のソリューション](<https://github.com/KazukiOnodera/Instacart>))

## 参考

- [Instacart Market Basket Analysis | Kaggle](<https://www.kaggle.com/c/instacart-market-basket-analysis>)
- [Kaggle - Instacart上位陣解法まとめ - Qiita](https://qiita.com/namakemono/items/6b719d38526a7b32dca1)
- [KazukiOnodera/Instacart: 2nd place solution🥕🥈](<https://github.com/KazukiOnodera/Instacart>)
- [sjvasquez/instacart-basket-prediction: Kaggle | Instacart Market Basket Analysis🥕🥉](<https://github.com/sjvasquez/instacart-basket-prediction>)
